
pqR version 2.15.1 (2019-07-05), based on R 2.15.0 (2012-03-30)

R 2.15.0 is Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

Modifications to R in pqR are Copyright (C) 2013-2019 Radford M. Neal

Some modules are from R-2.15.1 or later versions distributed by the R Core Team

Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.


No helper threads, task merging enabled, uncompressed pointers.

> # Compute the output of a network with two hidden layers
> # (with tanh activation function), when given 'x' as input.
> # Parameters are in the list 'L'.
> 
> nnet <- function (x, L)
+ {
+     h1 <- tanh (L$b1 + x %*% L$W1)
+     h2 <- tanh (L$b2 + h1 %*% L$W2)
+     as.vector (L$b3 + h2 %*% L$W3)
+ }
> 
> 
> # Train network with hidden layers of n1 and n2 units  on
> # data in X and y.  Initialize with std. dev. 'sd'.  Do
> # 'iters gradient descent iterations with stepsize 'step'.
> 
> train <- function (X, y, n1, n2, iters, step, sd=0.1)
+ {
+     # Initialize parameters randomly.
+ 
+     L <- list()
+     n0 <- ncol(X)
+     L$b1 <- rnorm (n1,sd=sd)
+     L$W1 <- matrix (rnorm(n0*n1,sd=sd), n0, n1)
+     L$b2 <- rnorm (n2,sd=sd)
+     L$W2 <- matrix (rnorm(n1*n2,sd=sd), n1, n2)
+     L$b3 <- rnorm (1,sd=sd)
+     L$W3 <- rnorm (n2,sd=sd)
+ 
+     # Train for 'iters' iterations to minimize squared 
+     # error predicting y.
+ 
+     for (i in 1:iters) {
+ 
+         # Find gradient of squared error (summed over all
+         # training examples) with respect to the parameters.
+ 
+         r <- with gradient (L) {
+             e <- 0
+             for (i in 1:nrow(X)) {
+                 o <- nnet (X[i,], L)
+                 e <- e + (y[i]-o)^2
+             }
+             e
+         }
+ 
+         g <- attr(r,"gradient")
+ 
+         if (i %% 100 == 0) 
+             cat ("Iteration", i, ": Error", round(r,4), "\n")
+ 
+         # Update parameters to reduce squared error.
+ 
+         L$b1 <- L$b1 - step * as.vector (g$b1)
+         L$W1 <- L$W1 - step * as.vector (g$W1)
+         L$b2 <- L$b2 - step * as.vector (g$b2)
+         L$W2 <- L$W2 - step * as.vector (g$W2)
+         L$b3 <- L$b3 - step * as.vector (g$b3)
+         L$W3 <- L$W3 - step * as.vector (g$W3)
+     }
+ 
+     L
+ }
> 
> 
> # Example of learning a 2D function.
> 
> set.seed(1)
> 
> pdf("smnn.pdf",width=8,height=4.6)
> par(mfrow=c(1,2))
> 
> truef <- function (X) cos (2*sqrt(X[,1]*X[,2])) - 2*(0.4-X[,1])^2
> 
> grid <- seq(0,1,length=101)
> Xgrid <- cbind (rep(grid,times=101), rep(grid,each=101))
> 
> contour (matrix(truef(Xgrid),101,101), levels=seq(-1,1,by=0.1))
> title("True function")
> 
> N <- 100
> X <- cbind (runif(N), runif(N))
> y <- truef (X) + rnorm(N,sd=0.01)
> 
> print (system.time (L <- train (X, y, 10, 10, 30000, 0.001)))
Iteration 100 : Error 14.3896 
Iteration 200 : Error 2.5427 
Iteration 300 : Error 2.352 
Iteration 400 : Error 2.2085 
Iteration 500 : Error 2.084 
Iteration 600 : Error 1.9662 
Iteration 700 : Error 1.848 
Iteration 800 : Error 1.7255 
Iteration 900 : Error 1.5968 
Iteration 1000 : Error 1.4622 
Iteration 1100 : Error 1.3236 
Iteration 1200 : Error 1.1845 
Iteration 1300 : Error 1.0492 
Iteration 1400 : Error 0.9226 
Iteration 1500 : Error 0.8087 
Iteration 1600 : Error 0.7101 
Iteration 1700 : Error 0.6279 
Iteration 1800 : Error 0.5612 
Iteration 1900 : Error 0.5081 
Iteration 2000 : Error 0.466 
Iteration 2100 : Error 0.4323 
Iteration 2200 : Error 0.4046 
Iteration 2300 : Error 0.3812 
Iteration 2400 : Error 0.3606 
Iteration 2500 : Error 0.3419 
Iteration 2600 : Error 0.3244 
Iteration 2700 : Error 0.3079 
Iteration 2800 : Error 0.2921 
Iteration 2900 : Error 0.2769 
Iteration 3000 : Error 0.2623 
Iteration 3100 : Error 0.2483 
Iteration 3200 : Error 0.235 
Iteration 3300 : Error 0.2225 
Iteration 3400 : Error 0.2109 
Iteration 3500 : Error 0.2002 
Iteration 3600 : Error 0.1904 
Iteration 3700 : Error 0.1816 
Iteration 3800 : Error 0.1738 
Iteration 3900 : Error 0.1669 
Iteration 4000 : Error 0.1609 
Iteration 4100 : Error 0.1558 
Iteration 4200 : Error 0.1514 
Iteration 4300 : Error 0.1477 
Iteration 4400 : Error 0.1446 
Iteration 4500 : Error 0.142 
Iteration 4600 : Error 0.1397 
Iteration 4700 : Error 0.1378 
Iteration 4800 : Error 0.1362 
Iteration 4900 : Error 0.1348 
Iteration 5000 : Error 0.1335 
Iteration 5100 : Error 0.1323 
Iteration 5200 : Error 0.1313 
Iteration 5300 : Error 0.1303 
Iteration 5400 : Error 0.1294 
Iteration 5500 : Error 0.1285 
Iteration 5600 : Error 0.1277 
Iteration 5700 : Error 0.1268 
Iteration 5800 : Error 0.126 
Iteration 5900 : Error 0.1252 
Iteration 6000 : Error 0.1244 
Iteration 6100 : Error 0.1236 
Iteration 6200 : Error 0.1227 
Iteration 6300 : Error 0.1219 
Iteration 6400 : Error 0.1211 
Iteration 6500 : Error 0.1203 
Iteration 6600 : Error 0.1194 
Iteration 6700 : Error 0.1186 
Iteration 6800 : Error 0.1178 
Iteration 6900 : Error 0.1169 
Iteration 7000 : Error 0.116 
Iteration 7100 : Error 0.1152 
Iteration 7200 : Error 0.1143 
Iteration 7300 : Error 0.1134 
Iteration 7400 : Error 0.1125 
Iteration 7500 : Error 0.1116 
Iteration 7600 : Error 0.1107 
Iteration 7700 : Error 0.1097 
Iteration 7800 : Error 0.1088 
Iteration 7900 : Error 0.1078 
Iteration 8000 : Error 0.1068 
Iteration 8100 : Error 0.1059 
Iteration 8200 : Error 0.1049 
Iteration 8300 : Error 0.1039 
Iteration 8400 : Error 0.1028 
Iteration 8500 : Error 0.1018 
Iteration 8600 : Error 0.1008 
Iteration 8700 : Error 0.0997 
Iteration 8800 : Error 0.0987 
Iteration 8900 : Error 0.0976 
Iteration 9000 : Error 0.0965 
Iteration 9100 : Error 0.0954 
Iteration 9200 : Error 0.0943 
Iteration 9300 : Error 0.0932 
Iteration 9400 : Error 0.0921 
Iteration 9500 : Error 0.0909 
Iteration 9600 : Error 0.0898 
Iteration 9700 : Error 0.0887 
Iteration 9800 : Error 0.0875 
Iteration 9900 : Error 0.0864 
Iteration 10000 : Error 0.0852 
Iteration 10100 : Error 0.0841 
Iteration 10200 : Error 0.0829 
Iteration 10300 : Error 0.0818 
Iteration 10400 : Error 0.0806 
Iteration 10500 : Error 0.0795 
Iteration 10600 : Error 0.0784 
Iteration 10700 : Error 0.0772 
Iteration 10800 : Error 0.0761 
Iteration 10900 : Error 0.075 
Iteration 11000 : Error 0.0739 
Iteration 11100 : Error 0.0729 
Iteration 11200 : Error 0.0718 
Iteration 11300 : Error 0.0707 
Iteration 11400 : Error 0.0697 
Iteration 11500 : Error 0.0687 
Iteration 11600 : Error 0.0677 
Iteration 11700 : Error 0.0668 
Iteration 11800 : Error 0.0658 
Iteration 11900 : Error 0.0649 
Iteration 12000 : Error 0.064 
Iteration 12100 : Error 0.0631 
Iteration 12200 : Error 0.0623 
Iteration 12300 : Error 0.0615 
Iteration 12400 : Error 0.0607 
Iteration 12500 : Error 0.06 
Iteration 12600 : Error 0.0592 
Iteration 12700 : Error 0.0585 
Iteration 12800 : Error 0.0579 
Iteration 12900 : Error 0.0572 
Iteration 13000 : Error 0.0566 
Iteration 13100 : Error 0.056 
Iteration 13200 : Error 0.0554 
Iteration 13300 : Error 0.0549 
Iteration 13400 : Error 0.0544 
Iteration 13500 : Error 0.0539 
Iteration 13600 : Error 0.0534 
Iteration 13700 : Error 0.053 
Iteration 13800 : Error 0.0525 
Iteration 13900 : Error 0.0521 
Iteration 14000 : Error 0.0517 
Iteration 14100 : Error 0.0514 
Iteration 14200 : Error 0.051 
Iteration 14300 : Error 0.0507 
Iteration 14400 : Error 0.0504 
Iteration 14500 : Error 0.0501 
Iteration 14600 : Error 0.0498 
Iteration 14700 : Error 0.0495 
Iteration 14800 : Error 0.0493 
Iteration 14900 : Error 0.049 
Iteration 15000 : Error 0.0488 
Iteration 15100 : Error 0.0485 
Iteration 15200 : Error 0.0483 
Iteration 15300 : Error 0.0481 
Iteration 15400 : Error 0.0479 
Iteration 15500 : Error 0.0477 
Iteration 15600 : Error 0.0475 
Iteration 15700 : Error 0.0473 
Iteration 15800 : Error 0.0472 
Iteration 15900 : Error 0.047 
Iteration 16000 : Error 0.0468 
Iteration 16100 : Error 0.0466 
Iteration 16200 : Error 0.0465 
Iteration 16300 : Error 0.0463 
Iteration 16400 : Error 0.0462 
Iteration 16500 : Error 0.046 
Iteration 16600 : Error 0.0459 
Iteration 16700 : Error 0.0457 
Iteration 16800 : Error 0.0456 
Iteration 16900 : Error 0.0455 
Iteration 17000 : Error 0.0453 
Iteration 17100 : Error 0.0452 
Iteration 17200 : Error 0.045 
Iteration 17300 : Error 0.0449 
Iteration 17400 : Error 0.0448 
Iteration 17500 : Error 0.0447 
Iteration 17600 : Error 0.0445 
Iteration 17700 : Error 0.0444 
Iteration 17800 : Error 0.0443 
Iteration 17900 : Error 0.0441 
Iteration 18000 : Error 0.044 
Iteration 18100 : Error 0.0439 
Iteration 18200 : Error 0.0438 
Iteration 18300 : Error 0.0436 
Iteration 18400 : Error 0.0435 
Iteration 18500 : Error 0.0434 
Iteration 18600 : Error 0.0433 
Iteration 18700 : Error 0.0432 
Iteration 18800 : Error 0.043 
Iteration 18900 : Error 0.0429 
Iteration 19000 : Error 0.0428 
Iteration 19100 : Error 0.0427 
Iteration 19200 : Error 0.0426 
Iteration 19300 : Error 0.0424 
Iteration 19400 : Error 0.0423 
Iteration 19500 : Error 0.0422 
Iteration 19600 : Error 0.0421 
Iteration 19700 : Error 0.042 
Iteration 19800 : Error 0.0419 
Iteration 19900 : Error 0.0417 
Iteration 20000 : Error 0.0416 
Iteration 20100 : Error 0.0415 
Iteration 20200 : Error 0.0414 
Iteration 20300 : Error 0.0413 
Iteration 20400 : Error 0.0412 
Iteration 20500 : Error 0.0411 
Iteration 20600 : Error 0.0409 
Iteration 20700 : Error 0.0408 
Iteration 20800 : Error 0.0407 
Iteration 20900 : Error 0.0406 
Iteration 21000 : Error 0.0405 
Iteration 21100 : Error 0.0404 
Iteration 21200 : Error 0.0402 
Iteration 21300 : Error 0.0401 
Iteration 21400 : Error 0.04 
Iteration 21500 : Error 0.0399 
Iteration 21600 : Error 0.0398 
Iteration 21700 : Error 0.0397 
Iteration 21800 : Error 0.0396 
Iteration 21900 : Error 0.0394 
Iteration 22000 : Error 0.0393 
Iteration 22100 : Error 0.0392 
Iteration 22200 : Error 0.0391 
Iteration 22300 : Error 0.039 
Iteration 22400 : Error 0.0389 
Iteration 22500 : Error 0.0388 
Iteration 22600 : Error 0.0386 
Iteration 22700 : Error 0.0385 
Iteration 22800 : Error 0.0384 
Iteration 22900 : Error 0.0383 
Iteration 23000 : Error 0.0382 
Iteration 23100 : Error 0.0381 
Iteration 23200 : Error 0.038 
Iteration 23300 : Error 0.0379 
Iteration 23400 : Error 0.0377 
Iteration 23500 : Error 0.0376 
Iteration 23600 : Error 0.0375 
Iteration 23700 : Error 0.0374 
Iteration 23800 : Error 0.0373 
Iteration 23900 : Error 0.0372 
Iteration 24000 : Error 0.0371 
Iteration 24100 : Error 0.0369 
Iteration 24200 : Error 0.0368 
Iteration 24300 : Error 0.0367 
Iteration 24400 : Error 0.0366 
Iteration 24500 : Error 0.0365 
Iteration 24600 : Error 0.0364 
Iteration 24700 : Error 0.0363 
Iteration 24800 : Error 0.0361 
Iteration 24900 : Error 0.036 
Iteration 25000 : Error 0.0359 
Iteration 25100 : Error 0.0358 
Iteration 25200 : Error 0.0357 
Iteration 25300 : Error 0.0356 
Iteration 25400 : Error 0.0355 
Iteration 25500 : Error 0.0353 
Iteration 25600 : Error 0.0352 
Iteration 25700 : Error 0.0351 
Iteration 25800 : Error 0.035 
Iteration 25900 : Error 0.0349 
Iteration 26000 : Error 0.0348 
Iteration 26100 : Error 0.0347 
Iteration 26200 : Error 0.0346 
Iteration 26300 : Error 0.0344 
Iteration 26400 : Error 0.0343 
Iteration 26500 : Error 0.0342 
Iteration 26600 : Error 0.0341 
Iteration 26700 : Error 0.034 
Iteration 26800 : Error 0.0339 
Iteration 26900 : Error 0.0338 
Iteration 27000 : Error 0.0336 
Iteration 27100 : Error 0.0335 
Iteration 27200 : Error 0.0334 
Iteration 27300 : Error 0.0333 
Iteration 27400 : Error 0.0332 
Iteration 27500 : Error 0.0331 
Iteration 27600 : Error 0.033 
Iteration 27700 : Error 0.0328 
Iteration 27800 : Error 0.0327 
Iteration 27900 : Error 0.0326 
Iteration 28000 : Error 0.0325 
Iteration 28100 : Error 0.0324 
Iteration 28200 : Error 0.0323 
Iteration 28300 : Error 0.0322 
Iteration 28400 : Error 0.032 
Iteration 28500 : Error 0.0319 
Iteration 28600 : Error 0.0318 
Iteration 28700 : Error 0.0317 
Iteration 28800 : Error 0.0316 
Iteration 28900 : Error 0.0315 
Iteration 29000 : Error 0.0314 
Iteration 29100 : Error 0.0313 
Iteration 29200 : Error 0.0311 
Iteration 29300 : Error 0.031 
Iteration 29400 : Error 0.0309 
Iteration 29500 : Error 0.0308 
Iteration 29600 : Error 0.0307 
Iteration 29700 : Error 0.0306 
Iteration 29800 : Error 0.0305 
Iteration 29900 : Error 0.0304 
Iteration 30000 : Error 0.0302 
   user  system elapsed 
 28.453   0.008  28.461 
> 
> print(L)
$b1
 [1]  0.03312670  0.20018262  0.24676223 -0.01408799 -0.13190646  0.95526175
 [7]  0.83734081  0.14606761 -0.02462760 -0.12726358

$W1
           [,1]        [,2]       [,3]       [,4]      [,5]         [,6]
[1,] 0.03525711  0.02912505 -0.3205619 -0.1552310 0.7020654 -1.278785502
[2,] 0.16116601 -0.30141713  0.7138095 -0.1129879 0.4641709  0.006622717
            [,7]       [,8]       [,9]      [,10]
[1,] -0.57090636 -0.4428152  0.1285794 0.08687519
[2,] -0.01354628  0.4079685 -0.4365000 0.15498818

$b2
 [1] -0.34293889 -0.20020641  0.02076739 -0.08903067 -0.43495754 -0.05843044
 [7]  0.19194693 -0.15688172  0.11293244 -0.01667223

$W2
             [,1]         [,2]        [,3]         [,4]        [,5]
 [1,]  0.08779067  0.040523120  0.12190410 -0.061563880  0.02924750
 [2,] -0.14039797 -0.020745646 -0.10311296 -0.003229727 -0.18405424
 [3,]  0.21705558  0.052428595  0.04972113 -0.005890708  0.20060872
 [4,] -0.06129124 -0.044846296  0.06087357  0.284234651 -0.08694759
 [5,]  0.50452272  0.199311250  0.26535208 -0.167779046  0.10651224
 [6,] -1.13926102  0.009698309 -0.05581614 -0.004507875 -0.83212193
 [7,] -0.68677196 -0.328046234 -0.09858379 -0.267336226 -0.46624918
 [8,] -0.04901414  0.055596435 -0.08361635  0.193690492  0.11070522
 [9,] -0.20787836 -0.030178901 -0.11118541 -0.171206670 -0.04524939
[10,]  0.30731707  0.024214413 -0.04041101  0.056122865  0.16223186
              [,6]        [,7]         [,8]        [,9]       [,10]
 [1,] -0.013375114  0.12756703  0.125794909  0.13362453 -0.01536123
 [2,]  0.028718694 -0.23224075 -0.003505478  0.25125999 -0.11206751
 [3,] -0.042199409  0.63576142 -0.109929119 -0.06981236 -0.16812393
 [4,] -0.174498230 -0.01580498 -0.091564538 -0.19233638  0.11904437
 [5,]  0.404113973 -0.09143451  0.210282645  0.09979008  0.16618030
 [6,] -0.083858353  0.37314551 -0.011172276  0.23772385  0.05606663
 [7,]  0.016377294  0.16520086 -0.131513875  0.09516465  0.07050044
 [8,] -0.012960203  0.47652817 -0.123339841 -0.10312035 -0.16417911
 [9,]  0.003282022 -0.35260490 -0.121651772  0.02247268  0.03444989
[10,]  0.004169573  0.04861305  0.090870529  0.02009523 -0.03499806

$b3
[1] -0.2336827

$W3
 [1] -1.3747102  0.2610998  0.2388467 -0.2731995 -0.5760811  0.3898746
 [7] -0.7763057  0.3582894  0.1255908  0.2315758

> 
> contour (
+   matrix (apply (Xgrid, 1, function (x) nnet (x, L)), 101, 101),
+   levels=seq(-1,1,by=0.1))
> title("Learned function")
> 
> 
> # Confirm that there's no allocation of large (eg, 10 x 100) 
> # intermediate Jacobian matrices when computing gradients of 
> # network parameters.
> 
> Rprofmemt(nelem=8)
> with gradient (L) nnet (c(0.3,0.6), L)
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):"nnet" 
RPROFMEM: 112 (double 10):
RPROFMEM: 112 (double 10):
RPROFMEM: 112 (double 10):
RPROFMEM: 112 (double 10):
RPROFMEM: 112 (double 10):
RPROFMEM: 192 (double 20):
RPROFMEM: 112 (double 10):
RPROFMEM: 112 (double 10):
RPROFMEM: 832 (double 100):
RPROFMEM: 112 (double 10):
[1] 0.6356475
attr(,"gradient")
attr(,"gradient")$b1
            [,1]      [,2]       [,3]        [,4]      [,5]      [,6]      [,7]
[1,] 0.004003755 0.1896742 -0.3356865 -0.09776494 0.1251752 0.5512103 0.2813416
           [,8]      [,9]      [,10]
[1,] -0.2890313 0.2143434 -0.2284704

attr(,"gradient")$W1
            [,1]        [,2]       [,3]      [,4]      [,5]       [,6]
[1,] 0.001201127 0.002402253 0.05690225 0.1138045 -0.100706 -0.2014119
            [,7]        [,8]       [,9]      [,10]     [,11]     [,12]
[1,] -0.02932948 -0.05865896 0.03755256 0.07510512 0.1653631 0.3307262
          [,13]    [,14]       [,15]      [,16]      [,17]    [,18]       [,19]
[1,] 0.08440248 0.168805 -0.08670939 -0.1734188 0.06430301 0.128606 -0.06854113
          [,20]
[1,] -0.1370823

attr(,"gradient")$b2
           [,1]      [,2]      [,3]       [,4]       [,5]      [,6]     [,7]
[1,] -0.5834784 0.2446103 0.2378599 -0.2553818 -0.2618058 0.3892174 -0.32583
          [,8]      [,9]     [,10]
[1,] 0.3447323 0.1144117 0.2310504

attr(,"gradient")$W2
            [,1]        [,2]       [,3]       [,4]       [,5]       [,6]
[1,] -0.08138827 -0.01637386 -0.3044885 0.07453831 -0.1999926 -0.3030936
           [,7]       [,8]      [,9]       [,10]      [,11]       [,12]   [,13]
[1,] -0.3366621 -0.1472862 0.1417819 0.004789153 0.03412022 0.006864373 0.12765
           [,14]      [,15]     [,16]     [,17]      [,18]       [,19]
[1,] -0.03124852 0.08384242 0.1270652 0.1411381 0.06174644 -0.05943889
            [,20]      [,21]      [,22]     [,23]       [,24]      [,25]
[1,] -0.002007745 0.03317861 0.00667494 0.1241273 -0.03038617 0.08152866
         [,26]     [,27]      [,28]       [,29]        [,30]       [,31]
[1,] 0.1235587 0.1372432 0.06004245 -0.05779858 -0.001952338 -0.03562271
            [,32]      [,33]      [,34]       [,35]      [,36]      [,37]
[1,] -0.007166648 -0.1332711 0.03262456 -0.08753445 -0.1326606 -0.1473531
           [,38]     [,39]       [,40]       [,41]        [,42]      [,43]
[1,] -0.06446546 0.0620563 0.002096157 -0.03651879 -0.007346924 -0.1366235
          [,44]       [,45]      [,46]      [,47]       [,48]      [,49]
[1,] 0.03344523 -0.08973636 -0.1359976 -0.1510598 -0.06608708 0.06361731
           [,50]      [,51]      [,52]     [,53]       [,54]     [,55]
[1,] 0.002148885 0.05429119 0.01092241 0.2031133 -0.04972183 0.1334078
         [,56]     [,57]     [,58]       [,59]        [,60]      [,61]
[1,] 0.2021828 0.2245752 0.0982493 -0.09457759 -0.003194671 -0.0454494
            [,62]      [,63]     [,64]      [,65]      [,66]      [,67]
[1,] -0.009143602 -0.1700346 0.0416242 -0.1116812 -0.1692556 -0.1880012
           [,68]      [,69]       [,70]      [,71]       [,72]     [,73]
[1,] -0.08224856 0.07917482 0.002674392 0.04808604 0.009674047 0.1798987
           [,74]     [,75]     [,76]     [,77]      [,78]       [,79]
[1,] -0.04403893 0.1181602 0.1790746 0.1989077 0.08702003 -0.08376797
            [,80]      [,81]       [,82]     [,83]       [,84]      [,85]
[1,] -0.002829541 0.01595907 0.003210677 0.0597058 -0.01461589 0.03921566
          [,86]      [,87]      [,88]       [,89]         [,90]      [,91]
[1,] 0.05943229 0.06601459 0.02888069 -0.02780138 -0.0009390838 0.03222877
          [,92]     [,93]       [,94]      [,95]     [,96]     [,97]      [,98]
[1,] 0.00648385 0.1205738 -0.02951627 0.07919465 0.1200214 0.1333141 0.05832355
           [,99]       [,100]
[1,] -0.05614392 -0.001896447

attr(,"gradient")$b3
[1] 1

attr(,"gradient")$W3
           [,1]       [,2]       [,3]       [,4]       [,5]       [,6]     [,7]
[1,] -0.7586584 -0.2513046 0.06427731 -0.2553793 -0.7386067 0.04105581 0.761762
           [,8]      [,9]      [,10]
[1,] -0.1945211 0.2983492 -0.0476319

> 
